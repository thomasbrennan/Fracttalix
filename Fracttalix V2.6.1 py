Fracttalix V2.6.1 py

import numpy as np
import pandas as pd
from scipy.stats import linregress
import argparse
import json
import sys
import warnings

# Optional for plotting
try:
    import matplotlib.pyplot as plt
    HAS_PLT = True
except ImportError:
    HAS_PLT = False

VERSION = "2.6.1"

def hurst_rs(ts):
    """Hurst exponent via R/S analysis (classic global estimator)"""
    ts = np.asarray(ts, dtype=float)
    N = len(ts)
    if N < 20:
        warnings.warn("Series too short for reliable Hurst (<20 points)")
        return np.nan
    cumdev = np.cumsum(ts - np.mean(ts))
    R = np.max(cumdev) - np.min(cumdev)
    S = np.std(ts)
    if S == 0:
        return np.nan
    return np.log(R / S) / np.log(N)

def higuchi_fd(ts, k_max=None):
    """Higuchi fractal dimension (Higuchi 1988) - 2 - slope for 1D time series"""
    ts = np.asarray(ts, dtype=float)
    N = len(ts)
    if N < 20:
        warnings.warn("Series too short for reliable Higuchi (<20 points)")
        return np.nan
    if k_max is None:
        k_max = int(np.sqrt(N))
        k_max = min(k_max, 50)
    L = []
    for k in range(1, k_max + 1):
        Lk = []
        for m in range(k):
            idx = np.arange(m, N, k)
            if len(idx) < 2:
                continue
            diffs = np.diff(ts[idx])
            n_points = len(idx) - 1
            Lmk = np.sum(np.abs(diffs)) * (N - 1) / (n_points * k)
            Lk.append(Lmk)
        if Lk:
            L.append(np.mean(Lk))
    if len(L) < 2:
        return np.nan
    log_L = np.log(L)
    log_k = np.log(1 / np.arange(1, len(L) + 1))
    slope, _, _, _, _ = linregress(log_k, log_L)
    return 2 - slope

def dfa(ts, scales=None):
    """Detrended Fluctuation Analysis exponent (Peng et al. 1994)"""
    ts = np.asarray(ts, dtype=float)
    N = len(ts)
    if N < 50:
        warnings.warn("Series too short for reliable DFA (<50 points)")
        return np.nan
    if scales is None:
        scales = np.logspace(1, np.log2(N//4), 8, base=2).astype(int)
    y = np.cumsum(ts - np.mean(ts))
    F = []
    for s in scales:
        if s >= N:
            continue
        fluctuations = []
        for i in range(0, N, s):
            segment = y[i:i+s]
            if len(segment) < 4:
                continue
            x = np.arange(len(segment))
            coeffs = np.polyfit(x, segment, 1)
            trend = np.polyval(coeffs, x)
            fluctuations.append(np.sqrt(np.mean((segment - trend)**2)))
        if fluctuations:
            F.append(np.mean(fluctuations))
    if len(F) < 2:
        return np.nan
    log_F = np.log(F)
    log_s = np.log(scales[:len(F)])
    slope, _, _, _, _ = linregress(log_s, log_F)
    return slope

def sample_entropy(ts, m=2, r=0.2):
    """Sample entropy (Richman & Moorman 2000)"""
    ts = np.asarray(ts, dtype=float)
    N = len(ts)
    if N < m + 1:
        warnings.warn("Series too short for sample entropy")
        return np.nan
    std = np.std(ts)
    if std == 0:
        return np.nan
    r = r * std

    def _phi(m):
        x = np.array([ts[i:i+m] for i in range(N-m)])
        dist = np.max(np.abs(x[:, None] - x[None, :]), axis=2)
        C = np.sum(dist <= r, axis=1)
        return np.sum(C) / (N - m)

    phi_m = _phi(m)
    phi_mp1 = _phi(m + 1)
    if phi_m == 0 or phi_mp1 == 0:
        return np.nan
    return -np.log(phi_mp1 / phi_m)

def petrosian_fd(ts):
    """Petrosian fractal dimension (Petrosian 1993)"""
    ts = np.asarray(ts, dtype=float)
    if len(ts) < 10:
        warnings.warn("Series too short for Petrosian FD")
        return np.nan
    diffs = np.diff(np.sign(np.diff(ts)))
    n_sign_changes = np.sum(np.abs(diffs) > 0)
    N = len(ts)
    return np.log10(N) / (np.log10(N) + np.log10(N / (N + 0.4 * n_sign_changes)))

def generate_pink(N):
    """Pink 1/f noise via FFT method (McCartney variant)"""
    white = np.random.randn(N)
    freq = np.fft.rfftfreq(N)
    freq[0] = freq[1] if len(freq) > 1 else 1  # avoid div0
    pink_fft = white / np.sqrt(np.abs(freq))
    pink = np.fft.irfft(pink_fft, n=N)
    pink = pink - np.mean(pink)
    return pink / np.std(pink)  # normalize

def linear_detrend(ts):
    """Simple linear detrend"""
    x = np.arange(len(ts))
    coeffs = np.polyfit(x, ts, 1)
    trend = np.polyval(coeffs, x)
    return ts - trend

def bootstrap_metric(ts, func, n_boot=100):
    """Bootstrap 95% CI for metric"""
    boots = []
    N = len(ts)
    for _ in range(n_boot):
        sample = np.random.choice(ts, N, replace=True)
        val = func(sample)
        if not np.isnan(val):
            boots.append(val)
    if len(boots) < 10:
        return np.nan, np.nan, np.nan
    mean = np.mean(boots)
    low = np.percentile(boots, 2.5)
    high = np.percentile(boots, 97.5)
    return mean, low, high

def stress_test():
    """Expanded stress-test with synthetic series, expected ranges, and status"""
    print("\nFracttalix v2.6.1 Stress-Test: Synthetic validation")
    print("-" * 60)
    np.random.seed(42)
    series = {
        "White noise": np.random.randn(1000),
        "Brownian motion": np.cumsum(np.random.randn(1000)),
        "Periodic sine": np.sin(np.linspace(0, 20*np.pi, 1000)),
        "Pink 1/f": generate_pink(1000),
        "Chaotic logistic (r=4)": np.array([0.5] + [4*x*(1-x) for x in np.random.rand(999)]),
    }
    expected = {
        "White noise": {"Hurst": (0.4, 0.6), "Higuchi": (1.4, 1.6), "DFA": (0.4, 0.6), "SampEn": (1.5, 2.5), "Petrosian": (1.4, 1.6)},
        "Brownian motion": {"Hurst": (0.7, 0.9), "Higuchi": (1.4, 1.6), "DFA": (0.9, 1.1), "SampEn": (0.5, 1.5), "Petrosian": (1.4, 1.6)},
        "Periodic sine": {"Hurst": (0.0, 0.3), "Higuchi": (1.0, 1.2), "DFA": (0.0, 0.2), "SampEn": (0.0, 0.5), "Petrosian": (1.0, 1.2)},
        "Pink 1/f": {"Hurst": (0.9, 1.1), "Higuchi": (1.4, 1.6), "DFA": (1.4, 1.6), "SampEn": (1.0, 2.0), "Petrosian": (1.4, 1.6)},
        "Chaotic logistic": {"Hurst": (0.0, 0.3), "Higuchi": (1.7, 1.9), "DFA": (0.0, 0.3), "SampEn": (1.8, 2.5), "Petrosian": (1.7, 1.9)},
    }
    for name, ts in series.items():
        print(f"\n{name}")
        metrics = {
            "Hurst": hurst_rs(ts),
            "Higuchi": higuchi_fd(ts),
            "DFA": dfa(ts),
            "SampEn": sample_entropy(ts),
            "Petrosian": petrosian_fd(ts),
        }
        for k, v in metrics.items():
            exp_range = expected.get(name, {}).get(k, None)
            status = "OK" if exp_range and exp_range[0] <= v <= exp_range[1] else "Out" if exp_range else "N/A"
            range_str = f"[{exp_range[0]:.1f}, {exp_range[1]:.1f}]" if exp_range else "N/A"
            print(f"  {k:12}: {v:.4f} ({status}) expected {range_str}")

def main():
    parser = argparse.ArgumentParser(description=f"Fracttalix v{VERSION} - Exploratory fractal/rhythmic metrics")
    parser.add_argument('file', nargs='?', help='CSV file (single or multi-column)')
    parser.add_argument('--col', type=int, default=0, help='Column index (0-based, default 0)')
    parser.add_argument('--plot', action='store_true', help='Plot the time series')
    parser.add_argument('--json', action='store_true', help='Output as JSON')
    parser.add_argument('--detrend', action='store_true', help='Linear detrend before analysis')
    parser.add_argument('--stress', action='store_true', help='Run expanded stress-test on synthetic series')
    parser.add_argument('--bootstrap', type=int, default=0, help='Bootstrap replicates for 95% CI (e.g., 100)')
    args = parser.parse_args()

    if args.stress:
        stress_test()
        sys.exit(0)

    if args.file:
        try:
            df = pd.read_csv(args.file)
            if args.col >= len(df.columns):
                print(f"Error: Column {args.col} not found")
                sys.exit(1)
            ts = df.iloc[:, args.col].dropna().values.astype(float)
        except Exception as e:
            print(f"Error reading file: {e}")
            sys.exit(1)
    else:
        print("No file - using synthetic random walk (Brownian motion)")
        np.random.seed(42)
        ts = np.cumsum(np.random.randn(1000))

    if len(ts) == 0:
        print("Error: Empty series")
        sys.exit(1)

    if args.detrend:
        ts = linear_detrend(ts)

    captured_warnings = []
    with warnings.catch_warnings(record=True) as w:
        warnings.simplefilter("always")
        base_metrics = {
            "Hurst (R/S)": hurst_rs(ts),
            "Higuchi FD": higuchi_fd(ts),
            "DFA exponent": dfa(ts),
            "Sample Entropy": sample_entropy(ts),
            "Petrosian FD": petrosian_fd(ts),
            "Length": len(ts),
            "Version": VERSION,
        }
        captured_warnings = [str(ww.message) for ww in w]

    output = {"metrics": base_metrics}
    if captured_warnings:
        output["warnings"] = captured_warnings

    if args.bootstrap > 0:
        boot_metrics = {}
        for name, func in [
            ("Hurst (R/S)", hurst_rs),
            ("Higuchi FD", higuchi_fd),
            ("DFA exponent", dfa),
            ("Sample Entropy", sample_entropy),
            ("Petrosian FD", petrosian_fd),
        ]:
            mean, low, high = bootstrap_metric(ts, func, args.bootstrap)
            boot_metrics[name] = {"mean": mean, "95% CI": (low, high)}
        output["bootstrap"] = boot_metrics

    if args.plot:
        if HAS_PLT:
            plt.figure(figsize=(10, 4))
            plt.plot(ts)
            plt.title("Time Series")
            plt.xlabel("Index")
            plt.ylabel("Value")
            plt.grid(True)
            plt.tight_layout()
            plt.show()
        else:
            print("Matplotlib not available - install for plotting")

    if args.json:
        print(json.dumps(output, indent=2))
    else:
        print(f"\nFracttalix v{VERSION} Metrics")
        print("-" * 50)
        for k, v in base_metrics.items():
            if k == "Version":
                continue
            if np.isnan(v):
                print(f"{k:20}: NaN")
            else:
                print(f"{k:20}: {v:.4f}")
        if args.bootstrap > 0:
            print("\nBootstrap 95% CI (mean [low, high])")
            print("-" * 50)
            for k, vals in boot_metrics.items():
                mean = vals["mean"]
                low, high = vals["95% CI"]
                print(f"{k:20}: {mean:.4f} [{low:.4f}, {high:.4f}]")
        if captured_warnings:
            print("\nWarnings:")
            for warn in captured_warnings:
                print(f"  - {warn}")

if __name__ == "__main__":
    main()

